{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import PIL.Image as PILI\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "  def __init__(self, image_size):\n",
    "    super(Learner, self).__init__()\n",
    "\n",
    "    eps = 1e-3\n",
    "    momentum = 0.95\n",
    "\n",
    "    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "    self.norm1 = nn.BatchNorm2d(32, eps, momentum)\n",
    "    self.relu1 = nn.ReLU(inplace=False)\n",
    "    self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "    self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "    self.norm2 = nn.BatchNorm2d(32, eps, momentum)\n",
    "    self.relu2 = nn.ReLU(inplace=False)\n",
    "    self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "    self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "    self.norm3 = nn.BatchNorm2d(32, eps, momentum)\n",
    "    self.relu3 = nn.ReLU(inplace=False)\n",
    "    self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "    self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "    self.norm4 = nn.BatchNorm2d(32, eps, momentum)\n",
    "    self.relu4 = nn.ReLU(inplace=False)\n",
    "    self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "    clr_in = image_size // 2**4\n",
    "    self.linear = nn.Linear(32 * clr_in * clr_in, 5)\n",
    "\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  def forward(self, x):\n",
    "    dx = self.conv1(x)\n",
    "    dx = self.norm1(dx)\n",
    "    dx = self.relu1(dx)\n",
    "    dx = self.pool1(dx)\n",
    "\n",
    "    dx = self.conv2(dx)\n",
    "    dx = self.norm2(dx)\n",
    "    dx = self.relu2(dx)\n",
    "    dx = self.pool2(dx)\n",
    "\n",
    "    dx = self.conv3(dx)\n",
    "    dx = self.norm3(dx)\n",
    "    dx = self.relu3(dx)\n",
    "    dx = self.pool3(dx)\n",
    "\n",
    "    dx = self.conv4(dx)\n",
    "    dx = self.norm4(dx)\n",
    "    dx = self.relu4(dx)\n",
    "    dx = self.pool4(dx)\n",
    "\n",
    "    dx = torch.reshape(dx, [dx.size(0), -1])\n",
    "    output = self.linear(dx)\n",
    "\n",
    "    return output\n",
    "\n",
    "  def get_params(self):\n",
    "    return torch.cat([p.view(-1) for p in self.parameters()], 0)\n",
    "  \n",
    "  def copy_params(self, cI):\n",
    "    idx = 0\n",
    "    for p in self.parameters():\n",
    "      plen = p.view(-1).size(0)\n",
    "      p.data.copy_(cI[idx: idx+plen].view_as(p))\n",
    "      idx += plen\n",
    "\n",
    "  def reset_batch_stats(self):\n",
    "      for m in self.modules():\n",
    "          if isinstance(m, nn.BatchNorm2d):\n",
    "              m.reset_running_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedLSTMCell(nn.Module):\n",
    "  def __init__(self, n_learner_parameters):\n",
    "    super(ModifiedLSTMCell,self).__init__()\n",
    "    self.input_size = 4\n",
    "    self.hidden_size = 20\n",
    "    self.n_learner_params = n_learner_parameters\n",
    "\n",
    "    self.cellIin = nn.Parameter(torch.Tensor(n_learner_parameters, 1))\n",
    "\n",
    "    self.inputWeight = nn.Parameter(torch.Tensor(self.input_size + 2, self.hidden_size))\n",
    "    self.forgetWeight = nn.Parameter(torch.Tensor(self.input_size + 2, 20))\n",
    "    \n",
    "    self.inputBias = nn.Parameter(torch.Tensor(1, self.hidden_size))\n",
    "    self.forgetBias = nn.Parameter(torch.Tensor(1, self.hidden_size))\n",
    "\n",
    "    self.reset_parameters()\n",
    "  \n",
    "  def forward(self, inputs, hx=None):\n",
    "    x_all, grad = inputs\n",
    "    batch, _ = x_all.size()\n",
    "\n",
    "    if hx is None:\n",
    "      f_prev = torch.zeros((batch, self.hidden_size)).to(self.forgetWeight.device)\n",
    "      i_prev = torch.zeros((batch, self.hidden_size)).to(self.inputWeight.device)\n",
    "      c_prev = self.cellIin\n",
    "      hx = [f_prev, i_prev, c_prev]\n",
    "\n",
    "    f_prev, i_prev, c_prev = hx\n",
    "    \n",
    "    f_next = torch.mm(torch.cat((x_all, c_prev, f_prev), 1), self.forgetWeight) + self.forgetBias.expand_as(f_prev)\n",
    "    i_next = torch.mm(torch.cat((x_all, c_prev, i_prev), 1), self.inputWeight) + self.inputBias.expand_as(i_prev)\n",
    "    c_next = torch.sigmoid(f_next).mul(c_prev) - torch.sigmoid(i_next).mul(grad)\n",
    "\n",
    "    return c_next, [f_next, i_next, c_next]\n",
    "\n",
    "  def reset_parameters(self):\n",
    "      for weight in self.parameters():\n",
    "          nn.init.uniform_(weight, -0.01, 0.01)\n",
    "      nn.init.uniform_(self.forgetBias, 4, 6)\n",
    "      nn.init.uniform_(self.inputBias, -5, -4)\n",
    "\n",
    "  def init_cI(self, flat_params):\n",
    "      self.cellIin.data.copy_(flat_params.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLearner(nn.Module):\n",
    "  def __init__(self, n_learner_params):\n",
    "    super(MetaLearner,self).__init__()\n",
    "    self.lstm = nn.LSTMCell(input_size=4, hidden_size=20)\n",
    "    self.metalstm = ModifiedLSTMCell(n_learner_parameters=n_learner_params)\n",
    "  \n",
    "  def forward(self, inputs, hs=None):\n",
    "    loss, grad_prep, grad = inputs\n",
    "    loss = loss.expand_as(grad_prep)\n",
    "    inputs = torch.cat((loss, grad_prep), 1)\n",
    "\n",
    "    if hs is None:\n",
    "      hs = [None, None]\n",
    "\n",
    "    hx, cx = self.lstm(inputs, hs[0])\n",
    "    learner_params, hs = self.metalstm([hx, grad], hs[1])\n",
    "\n",
    "    return learner_params.squeeze(), [(hx, cx), hs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodeDataset(data.Dataset):\n",
    "    def __init__(self, root, phase='train', n_shot=5, n_eval=15, transform=None):\n",
    "        root = os.path.join(root, phase)\n",
    "        self.labels = sorted(os.listdir(root))[1:]\n",
    "        images = [glob.glob(os.path.join(root, label, '*')) for label in self.labels]\n",
    "        self.episode_loader = [data.DataLoader(\n",
    "            ClassDataset(images=images[idx], label=idx, transform=transform),\n",
    "            batch_size=n_shot+n_eval, shuffle=True, num_workers=0) for idx, _ in enumerate(self.labels)]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return next(iter(self.episode_loader[idx]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "class ClassDataset(data.Dataset):\n",
    "    def __init__(self, images, label, transform=None):\n",
    "        self.images = images\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = PILI.open(self.images[idx]).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "class EpisodicSampler(data.Sampler):\n",
    "    def __init__(self, total_classes, n_class, n_episode):\n",
    "        self.total_classes = total_classes\n",
    "        self.n_class = n_class\n",
    "        self.n_episode = n_episode\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(self.n_episode):\n",
    "            yield torch.randperm(self.total_classes)[:self.n_class]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data_root, n_shot, n_eval, n_class, episode, episode_val):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    train_set = EpisodeDataset(data_root, 'train', n_shot, n_eval, transform=transforms.Compose([transforms.RandomResizedCrop(84), transforms.ToTensor(), normalize]))\n",
    "    val_set = EpisodeDataset(data_root, 'val', n_shot, n_eval, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "    test_set = EpisodeDataset(data_root, 'test', n_shot, n_eval, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "\n",
    "    train_loader = data.DataLoader(train_set, num_workers=0, batch_sampler=EpisodicSampler(len(train_set), n_class, episode))\n",
    "    val_loader = data.DataLoader(val_set, num_workers=0, batch_sampler=EpisodicSampler(len(val_set), n_class, episode_val))\n",
    "    test_loader = data.DataLoader(test_set, num_workers=0, batch_sampler=EpisodicSampler(len(test_set), n_class, episode_val))\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = prepare_data(\"./data/miniImagenet/\", 5, 15, 5, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 84\n",
    "bn_eps = 1e-3\n",
    "bn_momentum = 0.95\n",
    "n_class = 5\n",
    "n_eval = 15\n",
    "n_shot = 5\n",
    "grad_clip = 0.25\n",
    "lr = 1e-3\n",
    "epoch = 8\n",
    "batch_size = 25\n",
    "val_freq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_grad_loss(x):\n",
    "    p = 10\n",
    "    abs_x = x.abs()\n",
    "    sign_x = torch.sign(x)\n",
    "    eps = 1e-8\n",
    "    indicator = (abs_x >= np.exp(-p)).to(torch.float32)\n",
    "    x_1 = indicator * torch.log(abs_x + eps) / p + (1 - indicator) * (-1)\n",
    "    x_2 = indicator * sign_x + (1 - indicator) * (np.exp(p) * x)\n",
    "    return torch.stack([x_1, x_2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, dim=1)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum()\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res[0].item() if len(res) == 1 else [r.item() for r in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = []\n",
    "val_loss = []\n",
    "training_acc = []\n",
    "val_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_test(eval_loader, learner, metalearner):\n",
    "    for subeps, (episode_x, episode_y) in enumerate(eval_loader):\n",
    "        train_input = episode_x[:, :n_shot].flatten(0, 1).to(device)\n",
    "        train_target = torch.arange(n_class).repeat_interleave(n_shot).to(device)\n",
    "        test_input = episode_x[:, n_shot:].flatten(0, 1).to(device)\n",
    "        test_target = torch.arange(n_class).repeat_interleave(n_eval).to(device)\n",
    "\n",
    "        learner.reset_batch_stats()\n",
    "        learner.train()\n",
    "        cI = train_learner(learner, metalearner, train_input, train_target)\n",
    "\n",
    "        output = learner(test_input)\n",
    "        loss = learner.criterion(output, test_target)\n",
    "        acc = accuracy(output, test_target)\n",
    "    val_loss.append(loss.item())\n",
    "    val_acc.append(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_learner(learner, metalearner, train_input, train_target):\n",
    "  cI = metalearner.metalstm.cellIin.data\n",
    "  hs = [None]\n",
    "  for _ in range(epoch):\n",
    "    for i in range(0, len(train_input), batch_size):\n",
    "      x = train_input[i:i+batch_size]\n",
    "      y = train_target[i:i+batch_size]\n",
    "\n",
    "      learner.copy_params(cI)\n",
    "      output = learner(x)\n",
    "      loss = learner.criterion(output, y)\n",
    "      learner.zero_grad()\n",
    "      loss.backward()\n",
    "      grad = torch.cat([p.grad.data.view(-1) / batch_size for p in learner.parameters()], 0)\n",
    "\n",
    "      grad_prep = preprocess_grad_loss(grad)\n",
    "      loss_prep = preprocess_grad_loss(loss.data.unsqueeze(0))\n",
    "      metalearner_input = [loss_prep, grad_prep, grad.unsqueeze(1)]\n",
    "      cI, h = metalearner(metalearner_input, hs[-1])\n",
    "      hs.append(h)\n",
    "\n",
    "  return cI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(image_size).to(device) \n",
    "metalearner = MetaLearner(learner.get_params().size(0)).to(device)\n",
    "metalearner.metalstm.init_cI(learner.get_params())\n",
    "\n",
    "optim = torch.optim.Adam(metalearner.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "for eps, (episode_x, episode_y) in enumerate(train_loader):\n",
    "  train_input = episode_x[:, :n_shot].flatten(0, 1).to(device)\n",
    "  train_target = torch.LongTensor(np.repeat(range(n_class), n_shot)).to(device)\n",
    "  test_input = episode_x[:, n_shot:].flatten(0, 1).to(device)\n",
    "  test_target = torch.LongTensor(np.repeat(range(n_class), n_eval)).to(device)\n",
    "\n",
    "  learner.reset_batch_stats()\n",
    "  learner.train()\n",
    "  cI = train_learner(learner, metalearner, train_input, train_target)\n",
    "\n",
    "  output = learner(test_input)\n",
    "  loss = learner.criterion(output, test_target)\n",
    "  acc = accuracy(output, test_target)\n",
    "  training_loss.append(loss.item())\n",
    "  training_acc.append(acc)\n",
    "\n",
    "  optim.zero_grad()\n",
    "  loss.backward()\n",
    "  nn.utils.clip_grad_norm_(metalearner.parameters(), grad_clip)\n",
    "  optim.step()\n",
    "\n",
    "  if eps % 100 == 0 and eps != 0:\n",
    "    acc = meta_test(val_loader, learner, metalearner)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "    print(eps, \"val accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(training_loss))), training_loss)\n",
    "plt.plot(list(range(0, len(val_loss) * 100, 100)), val_loss)\n",
    "\n",
    "plt.xlabel(\"episode\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend((\"train\", 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(training_acc))), training_acc)\n",
    "plt.plot(list(range(0, len(val_acc) * 100, 100)), val_acc)\n",
    "\n",
    "plt.xlabel(\"episode\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend((\"train\", 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
